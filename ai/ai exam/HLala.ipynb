{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de2f8ec",
   "metadata": {},
   "source": [
    "video url: https://youtu.be/qI2jD712b-I?si=3Rb0qCLzsdAzL4d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7c5cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84865eac",
   "metadata": {},
   "source": [
    "### 1. Parameter-based experimetns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c2242",
   "metadata": {},
   "source": [
    "##### Confidence Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5aaa54fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a266ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"youtube_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30337ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.8690898418426514}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "    tokenizer=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    ")\n",
    "\n",
    "sentiment_pipeline(\"Bu mahnƒ± √ßox g√∂z…ôldir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51fe7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(text, threshold=0.6):\n",
    "    result = sentiment_pipeline(text[:512])[0] \n",
    "    label = result[\"label\"].lower()\n",
    "    score = result[\"score\"]\n",
    "\n",
    "    if score < threshold:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    if label == \"positive\":\n",
    "        return \"Positive\"\n",
    "    elif label == \"negative\":\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8a07ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_distribution(df, threshold):\n",
    "    sentiments = df[\"comment_text\"].apply(\n",
    "        lambda x: classify_sentiment(x, threshold)\n",
    "    )\n",
    "    return sentiments.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40e0a013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold = 0.6\n",
      "comment_text\n",
      "Neutral     57\n",
      "Positive    29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Threshold = 0.8\n",
      "comment_text\n",
      "Neutral     72\n",
      "Positive    14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dist_06 = sentiment_distribution(df, threshold=0.6)\n",
    "dist_08 = sentiment_distribution(df, threshold=0.8)\n",
    "\n",
    "print(\"\\nThreshold = 0.6\")\n",
    "print(dist_06)\n",
    "\n",
    "print(\"\\nThreshold = 0.8\")\n",
    "print(dist_08)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec874a5",
   "metadata": {},
   "source": [
    "##### Comment Length Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ddd6e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"youtube_comments.csv\")\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "    tokenizer=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0b0ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(text: str, threshold: float) -> str:\n",
    "    \"\"\"\n",
    "    Predict sentiment using the model.\n",
    "    If model confidence < threshold -> Neutral.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"Neutral\"\n",
    "\n",
    "    # Model input length safety\n",
    "    result = sentiment_pipeline(text[:512])[0]\n",
    "    label = result[\"label\"].lower()\n",
    "    score = float(result[\"score\"])\n",
    "\n",
    "    if score < threshold:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    if label == \"positive\":\n",
    "        return \"Positive\"\n",
    "    if label == \"negative\":\n",
    "        return \"Negative\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "def word_count(text: str) -> int:\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    return len(text.split())\n",
    "\n",
    "def run_length_filter_experiment(df: pd.DataFrame, min_words: int, threshold: float) -> dict:\n",
    "    \"\"\"\n",
    "    Filter by minimum word count, run sentiment classification,\n",
    "    return counts for Positive/Negative/Neutral and total N.\n",
    "    \"\"\"\n",
    "    filtered = df[df[\"comment_text\"].apply(word_count) >= min_words].copy()\n",
    "\n",
    "    sentiments = filtered[\"comment_text\"].apply(lambda t: classify_sentiment(t, threshold))\n",
    "    counts = sentiments.value_counts().to_dict()\n",
    "\n",
    "    return {\n",
    "        \"min_words\": min_words,\n",
    "        \"threshold\": threshold,\n",
    "        \"N\": len(filtered),\n",
    "        \"Positive\": counts.get(\"Positive\", 0),\n",
    "        \"Negative\": counts.get(\"Negative\", 0),\n",
    "        \"Neutral\": counts.get(\"Neutral\", 0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2d09afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results (Counts) ===\n",
      "   min_words  threshold   N  Positive  Negative  Neutral\n",
      "0          5        0.6  43         9         0       34\n",
      "1          5        0.8  43         3         0       40\n",
      "2          7        0.6  35         7         0       28\n",
      "3          7        0.8  35         3         0       32\n"
     ]
    }
   ],
   "source": [
    "MIN_WORD_FILTERS = [5, 7]\n",
    "THRESHOLDS = [0.6, 0.8]\n",
    "\n",
    "results = []\n",
    "for mw in MIN_WORD_FILTERS:\n",
    "    for th in THRESHOLDS:\n",
    "        results.append(run_length_filter_experiment(df, min_words=mw, threshold=th))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n=== Results (Counts) ===\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "783f51b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results (Percent %) ===\n",
      "   min_words  threshold   N  Positive  Negative  Neutral\n",
      "0          5        0.6  43     20.93       0.0    79.07\n",
      "1          5        0.8  43      6.98       0.0    93.02\n",
      "2          7        0.6  35     20.00       0.0    80.00\n",
      "3          7        0.8  35      8.57       0.0    91.43\n"
     ]
    }
   ],
   "source": [
    "pct_df = results_df.copy()\n",
    "for col in [\"Positive\", \"Negative\", \"Neutral\"]:\n",
    "    pct_df[col] = (pct_df[col] / pct_df[\"N\"] * 100).round(2)\n",
    "\n",
    "print(\"\\n=== Results (Percent %) ===\")\n",
    "print(pct_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b655c21",
   "metadata": {},
   "source": [
    "### 2. Analytical Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e3992",
   "metadata": {},
   "source": [
    "1.\tEmoji‚ÄìText Inconsistency. Identify comments where the sentiment expressed by emojis contradicts the sentiment of the textual content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd8845fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_EMOJIS = {\"‚ù§\", \"ü´†\", \"üòç\", \"üëè\", \"üòä\", \"ü©µ\", \"üéâ\", \"üòÖ\", \"ü•∞\", \"üòá\", \"üòå\", \"ü´∂\"}\n",
    "NEGATIVE_EMOJIS = {\"üò∂\", \"üò¢\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afca04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_sentiment(emojis):\n",
    "    if not isinstance(emojis, str) or not emojis.strip():\n",
    "        return \"Neutral\"\n",
    "\n",
    "    emoji_set = set(emojis.split())\n",
    "\n",
    "    if emoji_set & POSITIVE_EMOJIS:\n",
    "        return \"Positive\"\n",
    "    if emoji_set & NEGATIVE_EMOJIS:\n",
    "        return \"Negative\"\n",
    "    return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15b3092a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>emojis</th>\n",
       "      <th>text_sentiment</th>\n",
       "      <th>emoji_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dinl…ôy…ônd…ô m…ôn…ô d…ô x…ôb…ôr el…ôyin \"kims…ô ≈ü…ôrhini...</td>\n",
       "      <td>528</td>\n",
       "      <td>33</td>\n",
       "      <td>üò∂</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bu g√ºn m…ôn…ô bu mahnƒ±nƒ± ≈û√∂vk…ôt ∆èl…ôkb…ôrova yazma...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>‚ù§</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>H√ºsn√ºn…ô he√ß bir s√∂z olmaz\\r\\nG√∂zl…ôrin yaman g√∂...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ù§</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sanƒ±ram d√ºnya m…ônimdir, 'g√∂z√ºm…ô' -'g√∂z√ºn' d…ôy…ô...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>ü´†</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sizin mahnƒ±larƒ±nƒ±zƒ± √ßox sevir…ôm ancaq indi siz‚Ä¶</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ù§</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         comment_text  like_count  \\\n",
       "0   Dinl…ôy…ônd…ô m…ôn…ô d…ô x…ôb…ôr el…ôyin \"kims…ô ≈ü…ôrhini...         528   \n",
       "3   Bu g√ºn m…ôn…ô bu mahnƒ±nƒ± ≈û√∂vk…ôt ∆èl…ôkb…ôrova yazma...           2   \n",
       "9   H√ºsn√ºn…ô he√ß bir s√∂z olmaz\\r\\nG√∂zl…ôrin yaman g√∂...           0   \n",
       "11  sanƒ±ram d√ºnya m…ônimdir, 'g√∂z√ºm…ô' -'g√∂z√ºn' d…ôy…ô...           4   \n",
       "13    Sizin mahnƒ±larƒ±nƒ±zƒ± √ßox sevir…ôm ancaq indi siz‚Ä¶           2   \n",
       "\n",
       "    reply_count emojis text_sentiment emoji_sentiment  \n",
       "0            33      üò∂        Neutral        Negative  \n",
       "3             1      ‚ù§        Neutral        Positive  \n",
       "9             0      ‚ù§        Neutral        Positive  \n",
       "11            0      ü´†        Neutral        Positive  \n",
       "13            0      ‚ù§        Neutral        Positive  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_sentiment\"] = df[\"comment_text\"].apply(lambda t: classify_sentiment(t, threshold=0.6))\n",
    "df[\"emoji_sentiment\"] = df[\"emojis\"].apply(emoji_sentiment)\n",
    "\n",
    "inconsistent = df[\n",
    "    (df[\"text_sentiment\"] != df[\"emoji_sentiment\"]) & (df[\"emoji_sentiment\"] != \"Neutral\")\n",
    "]\n",
    "\n",
    "inconsistent.to_csv(\"emojiText_inconsistency.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "inconsistent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40905725",
   "metadata": {},
   "source": [
    "2.\tSemantically Similar Comments. Identify groups of comments with high semantic similarity (e.g., using cosine similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40127a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "17e456ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 040e70c4-954e-4719-80c8-e7cd57e0746b)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: a4ee8a6e-b63e-4e3c-934b-376a514429d9)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    group_id  comment_index                                       comment_text\n",
      "0          1              5  Allah r…ôhm…ôt el…ôsin dahi Az…ôrbaycan m√ºƒü…ônnisi ...\n",
      "1          1              8  M…ôn M…ôn Az…ôrbaycanƒ± √ßox sevir…ôm, ya≈üasƒ±n qarda...\n",
      "2          1             10  Allah s…ôn…ô r…ôhm…ôt el…ôsin Dahi S…ôn…ôtkarƒ±mƒ±z ≈û√∂v...\n",
      "3          1             14  Az…ôrbaycanƒ±n Musiqimizin Zeyn…ôb Xanlarova ≈û√∂vk...\n",
      "4          1             36  Allah r…ôhm…ôt el…ôsin m…ôkan c…ônn…ôt olsun  g√∂z…ôl ...\n",
      "5          1             19  Nec…ô g√∂z…ôl , s…ôlist , dialekt…ô , ≈üiv…ôy…ô maraql...\n",
      "6          1             24  Normalda Azerbaycan mahnƒ±larƒ± sevm…ôr…ôm hel…ô in...\n",
      "7          1             32  AZ∆èRBAYCANIN M∆èD∆èNƒ∞YY∆èTƒ∞N∆è E≈ûQ  OLSUN. USTADLA...\n",
      "8          1             58  Beh beh.En √ßox dinl…ôdiyim …ôs…ôr.S…ôni m…ôn yaman ...\n",
      "9          1              7  Musiqi, ifa, ifa√ßƒ± g√∂z…ôl t…ôbii biz n…ôl…ôr itirm...\n",
      "10         2             31                                    ∆èn g√∂z…ôl mahnƒ± \n",
      "11         2             41                      …ôn sevdiyim mahnƒ±larƒ±n biriii\n",
      "12         2             42                                        G√∂z…ôl mahnƒ±\n",
      "13         2             46                                  √áox q…ô≈ü…ôqdi mahnƒ±\n",
      "14         2             62                                      G√∂z…ôl mahnƒ±dƒ±\n",
      "15         3             51                                        √áox g√∂z…ôldi\n",
      "16         3             64                                   √áox g√∂z…ôldi axƒ±ƒ±\n",
      "17         3             66                                          √áox g√∂z…ôl\n",
      "18         3             72                                 Mahnƒ± √ßox g√∂z…ôldir\n",
      "19         4             20             ALLAH r…ôhm…ôt el…ôsin s…ôn…ô dahi sen…ôtkar\n",
      "20         4             26                                Allah r…ôhm…ôt el…ôsin\n",
      "21         4             28                       M√ºk…ônm…ôll allah r…ôhm…ôt etsin\n",
      "22         5             48                                                ∆èla\n",
      "23         5             53                                                ∆èla\n",
      "24         5             73                                                ∆èla\n",
      "25         6             11  sanƒ±ram d√ºnya m…ônimdir, 'g√∂z√ºm…ô' -'g√∂z√ºn' d…ôy…ô...\n",
      "26         6             22     sanaram d√ºnya m…ônimdir,g√∂z√ºn…ô g√∂z√ºm d…ôy…ônd…ô...\n",
      "27         7             57                                    N…ô g√∂z…ôl oxuyur\n",
      "28         7             80                                  √áox g√∂z…ôl oxuyur \n",
      "29         8             59                                 √áox g√∂z…ôl s…ôsi var\n",
      "Saved: semantic_similarity_groups.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "texts = df[\"comment_text\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "embeddings = model.encode(texts, show_progress_bar=True)\n",
    "sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "THRESHOLD = 0.85\n",
    "n = len(texts)\n",
    "\n",
    "adj = defaultdict(list)\n",
    "for i in range(n):\n",
    "    for j in range(i + 1, n):\n",
    "        if sim_matrix[i, j] >= THRESHOLD:\n",
    "            adj[i].append(j)\n",
    "            adj[j].append(i)\n",
    "\n",
    "visited = set()\n",
    "groups = []\n",
    "\n",
    "for i in range(n):\n",
    "    if i in visited:\n",
    "        continue\n",
    "    if i not in adj:\n",
    "        visited.add(i)\n",
    "        continue\n",
    "\n",
    "    q = deque([i])\n",
    "    visited.add(i)\n",
    "    comp = [i]\n",
    "\n",
    "    while q:\n",
    "        u = q.popleft()\n",
    "        for v in adj[u]:\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                q.append(v)\n",
    "                comp.append(v)\n",
    "\n",
    "    groups.append(comp)\n",
    "\n",
    "group_rows = []\n",
    "for g_id, idxs in enumerate(sorted(groups, key=len, reverse=True), start=1):\n",
    "    for idx in idxs:\n",
    "        group_rows.append({\n",
    "            \"group_id\": g_id,\n",
    "            \"comment_index\": idx,\n",
    "            \"comment_text\": texts[idx]\n",
    "        })\n",
    "\n",
    "groups_df = pd.DataFrame(group_rows)\n",
    "print(groups_df.head(30))\n",
    "\n",
    "groups_df.to_csv(\"semantic_similarity_groups.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved: semantic_similarity_groups.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f650505",
   "metadata": {},
   "source": [
    "3.\tSemantic Outliers. How many comments significantly deviate from the overall semantic similarity distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fbd830be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_similarity = sim_matrix.mean(axis=1)\n",
    "\n",
    "threshold = avg_similarity.mean() - 2 * avg_similarity.std()\n",
    "outliers = np.where(avg_similarity < threshold)[0]\n",
    "\n",
    "len(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73094dc8",
   "metadata": {},
   "source": [
    "4.\tPopular Comment Analysis. Identify common words or phrases used in comments with the highest number of likes and replies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c15c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff540aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bir', 7),\n",
       " ('g√∂z…ôl', 6),\n",
       " ('bu', 5),\n",
       " ('r…ôhm…ôt', 5),\n",
       " ('d…ô', 4),\n",
       " ('allah', 4),\n",
       " ('el…ôsin', 4),\n",
       " ('√ßox', 4),\n",
       " ('qulaq', 3),\n",
       " ('m…ôn…ô', 2)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_comments = df.sort_values(\n",
    "    by=[\"like_count\", \"reply_count\"],\n",
    "    ascending=False\n",
    ").head(20)\n",
    "\n",
    "words = []\n",
    "for text in top_comments[\"comment_text\"]:\n",
    "    words.extend(text.lower().split())\n",
    "\n",
    "Counter(words).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8372eb91",
   "metadata": {},
   "source": [
    "### 3. Semantic Category-Based Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "61fc6981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_category(text, sentiment, emojis):\n",
    "    t = text.lower()\n",
    "\n",
    "    if sentiment == \"Negative\" and any(w in t for w in [\"pis\", \"z…ôif\", \"b…ôy…ônm…ôdim\", \"s…ôhv\"]):\n",
    "        return \"Criticism and dissatisfaction\"\n",
    "\n",
    "    if any(w in t for w in [\"s…ôn\", \"siz\", \"kanal\", \"video\", \"s…ôsiniz\", \"mahnƒ±\", \"Mahnƒ±\"]):\n",
    "        return \"Direct address to the author\"\n",
    "\n",
    "    if any(w in t for w in [\"haha\", \"bo≈ü\", \"???\"]):\n",
    "        return \"Troll / non-constructive comment\"\n",
    "\n",
    "    if sentiment == \"Positive\" and (emojis or any(w in t for w in [\"…ôla\", \"super\", \"m√∂ht…ô≈ü…ôm\", \"≈üedevr\", \"bravo\"])):\n",
    "        return \"Emotional reaction\"\n",
    "\n",
    "    if sentiment == \"Positive\":\n",
    "        return \"Rational positive feedback on content\"\n",
    "\n",
    "    return \"Emotional reaction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "92f14cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"semantic_category\"] = df.apply(\n",
    "    lambda row: semantic_category(\n",
    "        row[\"comment_text\"],\n",
    "        row[\"text_sentiment\"],\n",
    "        row[\"emojis\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9bb1ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_sentiment                Neutral  Positive\n",
      "semantic_category                              \n",
      "Direct address to the author       19         8\n",
      "Emotional reaction                 38        21\n"
     ]
    }
   ],
   "source": [
    "result_table = (\n",
    "    df.groupby([\"semantic_category\", \"text_sentiment\"])\n",
    "      .size()\n",
    "      .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "print(result_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
